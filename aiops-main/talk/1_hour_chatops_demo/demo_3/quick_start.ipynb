{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling 简单示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatGPT want to call function:  ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Ovg09I5nKPmTw6Sb7qbaX9es', function=Function(arguments='{\"query_str\":\"{app=\\\\\"grafana\\\\\"} |= \\\\\"Error\\\\\"\"}', name='analyze_loki_log'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 定义函数列表，同时在代码里实现该函数\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_loki_log\",\n",
    "            \"description\": \"从 Loki 获取日志\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query_str\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": 'Loki 查询字符串，例如：{app=\"grafana\"} |= \"Error\"',\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query_str\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "def analyze_loki_log(query_str):\n",
    "    print(\"调用 analyze_loki_log 函数，入参：\", query_str)\n",
    "    print(\"进入函数调用获取日志\")\n",
    "    return \"没有找到相关日志\"\n",
    "\n",
    "user_input = \"查看 app=grafana 且关键字包含 Error 的日志\"\n",
    "# 系统提示语和用户消息\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"你是一个 Loki 日志分析助手，你可以帮助用户分析 Loki 日志，你可以调用多个函数来帮助用户完成任务，并最终尝试分析错误产生的原因\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input,\n",
    "    },\n",
    "]\n",
    "\n",
    "# 步骤1：你的代码调用大模型 API，并将系统提示语、用户输入、函数列表及其功能描述一并传递给大模型\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=message,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "# 步骤2：大模型根据需求决定调用几个或多个方法来完成任务\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "# 步骤 3：大模型返回给业务要调用的函数以及函数的入参消息\n",
    "print(\"\\nChatGPT want to call function: \", response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调用 analyze_loki_log 函数，入参： {app=\"grafana\"} |= \"Error\"\n",
      "进入函数调用获取日志\n",
      "函数返回结果:  没有找到相关日志\n",
      "第五步-最终推理:  没有找到包含“Error”关键字的 Grafana 日志。\n"
     ]
    }
   ],
   "source": [
    "# 解析函数调用消息，如果有多个函数调用，则循环调用\n",
    "tool_calls = response_message.tool_calls\n",
    "for tool_call in tool_calls:\n",
    "    tool_call_id = tool_call.id\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    # 步骤4：你的业务代码用大模型给的参数和入参自行调用函数\n",
    "    function_response = globals()[function_name](**function_args)\n",
    "    print(\"函数返回结果: \",function_response)\n",
    "\n",
    "    # 步骤5：用调用结果再次调用大模型 API，让大模型生成语义化的回复\n",
    "\n",
    "    \"\"\"\n",
    "    注意再次调用大模型时，需传递所有的历史消息，包括系统消息、用户消息、函数调用消息、函数调用返回\n",
    "    \"\"\"\n",
    "    # 加入刚才的系统提示语\n",
    "    new_message = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"基于函数调用结果回答问题，如果函数调用结果不足以回答问题，不要编造，就说不清楚、不知道。\",\n",
    "        }\n",
    "    ]\n",
    "    # 把用户消息也加入进来\n",
    "    new_message.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input,\n",
    "        }\n",
    "    )\n",
    "    # 把前面 LLM 返回的函数调用消息也加进来\n",
    "    new_message.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"tool_calls\": tool_calls,\n",
    "        }\n",
    "    )\n",
    "    # 最后是函数回复消息\n",
    "    new_message.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )\n",
    "    # 再次调用大模型，得到最终回复\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=new_message,\n",
    "    )\n",
    "    print(\"第五步-最终推理: \",final_response.choices[0].message.content)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
